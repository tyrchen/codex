# Idea

Please carefully study current repo, and add a new crate `codex-agent-lib` which encapsulate existing codex crate, expose all the tools codex provided, that could be used like this (high level idea, feel free to tune api as needed). The ultimate goal is to use it easily in other projects:

```rust
use codex_agent_lib::{Agent, AgentConfig};
use tokio::sync::mpsc;
use typed_builder::TypedBuilder;

struct InputMessage {
    message: String,
}

struct OutputMessage {
    turn_id: u64,
    data: OutputData,
}

enum OutputData {
    Start,
    Primary(String),
    Detail(String),
    Completed,
    Error(OutputError),
}

enum OutputError {
    TurnLimitExceeded,
    ToolError(String),
    ...
}

async fn main() {
  let config = AgentConfig::builder() // typed builder
      .model("gpt-5-mini")
      .api_key(std::env::var("OPENAI_API_KEY").unwrap())
      .system_prompt("You are a helpful assistant.")
      .tools(vec![bash_tool, web_search_tool, ...])
      .mcp_servers(vec![mcp_server1, mcp_server2, ...])
      .build();

  let agent = Agent::new(config);

  let (input_tx, input_rx) = mpsc::channel::<InputMessage>(100); // input message
  let (output_tx, output_rx) = mpsc::channel::<OutputMessage>(100); // output result contains message or error

  // it will break down user's intention to tasks, and run each turn, auto heal if error, until it finished task or return an Result
  agent.execute(input_tx, output_rx).await.unwrap;

  input_tx.send("Hello, how are you?").await.unwrap();
  while let Some(output) = output_rx.recv().await {
    match output.data {
      OutputData::Primary(message) => println!("{}", message),
      OutputData::Detail(message) => println!("{}", message),
      OutputData::Completed => println!("Completed"),
      OutputData::Error(error) => println!("Error: {}", error),
    }
  }
}
```

codex-lib agent should be able to stop / pause / resume / restart. besides using existing builtin tools, users could add new tools or register mcp servers and integrate easily.
